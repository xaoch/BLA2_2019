{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Risk and Uncertainty\n\nThe first part of this tutorial will show how can we use clustering to create a risk predictor with an associated measurement of its uncertainty.\n\nFirst, we will load two datasets.  The first one contains information about students and their performance in different groups of courses.  The second have information about the type of semesters that these students took.\n\nLet's start loading the required libraries in Python"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy\nfrom sklearn import cluster\nfrom sklearn.metrics import brier_score_loss\nfrom sklearn.calibration import calibration_curve\nimport matplotlib.pyplot as plt",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, let's load the student information"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "students = pd.read_csv(\"students.csv\")\nstudents.head()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>student_id</th>\n      <th>factor1</th>\n      <th>factor2</th>\n      <th>factor3</th>\n      <th>factor4</th>\n      <th>factor5</th>\n      <th>gpa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>691c86211b9332626f9fe928166a3ebc</td>\n      <td>3.575789</td>\n      <td>3.072500</td>\n      <td>6.350000</td>\n      <td>0.00</td>\n      <td>4.575000</td>\n      <td>4.74</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>e8d43918176368313368e5d6590d7b2e</td>\n      <td>4.648125</td>\n      <td>4.047778</td>\n      <td>6.220000</td>\n      <td>7.75</td>\n      <td>5.250000</td>\n      <td>8.40</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4c8f414a7312185477484c679144f284</td>\n      <td>5.223333</td>\n      <td>6.007143</td>\n      <td>6.793333</td>\n      <td>7.16</td>\n      <td>5.723333</td>\n      <td>6.33</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>247ff15b0c0537e2f118bcc27692ced5</td>\n      <td>6.566000</td>\n      <td>4.996000</td>\n      <td>6.633333</td>\n      <td>2.09</td>\n      <td>8.415000</td>\n      <td>5.63</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>f7f153c13c2bc64f850f702aa7f48077</td>\n      <td>2.819444</td>\n      <td>0.750000</td>\n      <td>5.093333</td>\n      <td>0.00</td>\n      <td>3.562000</td>\n      <td>6.20</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   Unnamed: 0                        student_id   factor1   factor2   factor3  \\\n0           1  691c86211b9332626f9fe928166a3ebc  3.575789  3.072500  6.350000   \n1           2  e8d43918176368313368e5d6590d7b2e  4.648125  4.047778  6.220000   \n2           3  4c8f414a7312185477484c679144f284  5.223333  6.007143  6.793333   \n3           4  247ff15b0c0537e2f118bcc27692ced5  6.566000  4.996000  6.633333   \n4           5  f7f153c13c2bc64f850f702aa7f48077  2.819444  0.750000  5.093333   \n\n   factor4   factor5   gpa  \n0     0.00  4.575000  4.74  \n1     7.75  5.250000  8.40  \n2     7.16  5.723333  6.33  \n3     2.09  8.415000  5.63  \n4     0.00  3.562000  6.20  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<font color=\"darkblue\">**Explanation:**\n<ul>\n<li>The students.csv file contains the following information:\n<li>*student_id*: Student identification\n<li>*factor1*: The average grade of the students in courses that belong to the first factor\n<li>*factor2*: The average grade of the students in courses that belong to the second factor\n<li>*factor3*: The average grade of the students in courses that belong to the third factor\n<li>*factor4*: The average grade of the students in courses that belong to the fourth factor\n<li>*factor5*: The average grade of the students in courses that belong to the fifth factor\n<li>*gpa*: General average of the student's grades\n</ul>\n</font>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, we can load the semester information"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "semesters = pd.read_csv(\"semesters.csv\")\nsemesters.head()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>semester_id</th>\n      <th>student_id</th>\n      <th>fail</th>\n      <th>year</th>\n      <th>order</th>\n      <th>semester</th>\n      <th>beta_total</th>\n      <th>num_classes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>97d4d28f8412b1651e17042791b5bd84</td>\n      <td>True</td>\n      <td>1978</td>\n      <td>1</td>\n      <td>1S</td>\n      <td>0.072262</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>97d4d28f8412b1651e17042791b5bd84</td>\n      <td>False</td>\n      <td>1978</td>\n      <td>2</td>\n      <td>2S</td>\n      <td>1.443359</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>2</td>\n      <td>97d4d28f8412b1651e17042791b5bd84</td>\n      <td>True</td>\n      <td>1979</td>\n      <td>3</td>\n      <td>1S</td>\n      <td>0.919784</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>3</td>\n      <td>97d4d28f8412b1651e17042791b5bd84</td>\n      <td>True</td>\n      <td>1979</td>\n      <td>4</td>\n      <td>2S</td>\n      <td>0.213528</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>4</td>\n      <td>97d4d28f8412b1651e17042791b5bd84</td>\n      <td>True</td>\n      <td>1980</td>\n      <td>5</td>\n      <td>1S</td>\n      <td>-0.428132</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   Unnamed: 0  semester_id                        student_id   fail  year  \\\n0           1            0  97d4d28f8412b1651e17042791b5bd84   True  1978   \n1           2            1  97d4d28f8412b1651e17042791b5bd84  False  1978   \n2           3            2  97d4d28f8412b1651e17042791b5bd84   True  1979   \n3           4            3  97d4d28f8412b1651e17042791b5bd84   True  1979   \n4           5            4  97d4d28f8412b1651e17042791b5bd84   True  1980   \n\n   order semester  beta_total  num_classes  \n0      1       1S    0.072262            5  \n1      2       2S    1.443359            4  \n2      3       1S    0.919784            4  \n3      4       2S    0.213528            4  \n4      5       1S   -0.428132            3  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<font color=\"darkblue\">**Explanation:**\n<ul>\n<li>The semesters.csv file contains the following information:\n<li>*student_id*: Student identification\n<li>*fail*: If the student have failed at least 1 course during the semester\n<li>*year*: Year in which the semester was taken\n<li>*order*: Number of the semester for that students (first, second, third, etc.)\n<li>*semester*: The first \"1S\" or second \"2S\" semester of the year\n<li>*beta_total*: Addition of the beta (difficulty) of all the courses taken that semester\n<li>*num_classes*: Total number of classes taken that semester\n</ul>\n</font>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# We will now create a model to predict the risk of students taking the course.  This model will be based on clustering.\n\nThe general idea of the model is:  \n* To predict the risk that a student will fail at least one course in a given semester,\n* First, we find students that are similar to the student.  To do this we need to cluster the students and find out in which cluster the student is.\n* Second, from all the students that are in the same cluster, we find which of them have taken similar semester to the one being propose.\n* We calculate the proportion of similar students, that have taken similar semesters that have failed.\n* Finally, we assign this proportion as the probability of the proposed student, failed the proposed semester.\n\nLet's first separate the data into a train and test set.  To create a realistic prediction, we will use only data before 2012 to train the model and we use data from 2012 onwards to test the model.  It will be similar to train the model with all the existing information and making prediction for new student-semesters."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "semesters_train=semesters[semesters['year'] < 2012]\nsemesters_test=semesters[semesters['year'] > 2011]\n\nstudents_train=students[students['student_id'].isin(semesters_train['student_id'].tolist())]\nstudents_test=students[students['student_id'].isin(semesters_test['student_id'].tolist())]\n\nstudents_test_ids=students_test['student_id'].tolist()\n\nsemesters_test=semesters_test[semesters_test['student_id'].isin(students_test_ids)]",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "vector_students=students_train[['factor1', 'factor2','factor3','factor4','factor5','gpa']]\nk_clusters = 5\n\nclus_students = cluster.KMeans(n_clusters=k_clusters, n_init=200)\nclus_students.fit(vector_students)\nstudents_train[\"cluster\"]=clus_students.labels_",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "vector_semesters=semesters_train[['order', 'beta_total','num_classes']]\nk_clusters = 8\n\nclus_semesters = cluster.KMeans(n_clusters=k_clusters, n_init=200)\nclus_semesters.fit(vector_semesters)\nsemesters_train[\"cluster\"]=clus_semesters.labels_",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, lets predict the cluster for each one of these students after 2012"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "vector_students=students_test[['factor1', 'factor2','factor3','factor4','factor5','gpa']]\npredicted_cluster=clus_students.predict(vector_students)\nstudents_test[\"cluster\"]=predicted_cluster\n\nvector_semesters=semesters_test[['order', 'beta_total','num_classes']]\npredicted_cluster=clus_semesters.predict(vector_semesters)\nsemesters_test[\"cluster\"]=predicted_cluster",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  app.launch_new_instance()\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_risk(semester_id):\n    semester=semesters_test[semesters_test[\"semester_id\"]==semester_id]\n    student_id=semester[\"student_id\"].values[0]\n    student_info=students_test[students_test[\"student_id\"]==student_id]\n    cluster_student=student_info[\"cluster\"].values[0]\n    similar_students=students_train[students_train[\"cluster\"]==cluster_student]\n    similar_students_ids=similar_students[\"student_id\"].tolist()\n    semester_cluster=semester[\"cluster\"].values[0]\n    selected_semesters=semesters_train[semesters_train[\"student_id\"].isin(similar_students_ids)]\n    selected_semesters=selected_semesters[selected_semesters['cluster']==semester_cluster]\n    total_cases=len(selected_semesters)\n    failed_cases=len(selected_semesters[selected_semesters['fail']==True])\n    risk=failed_cases/total_cases\n    return risk",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "semesters_test[\"risk_prediction\"]=semesters_test['semester_id'].apply(lambda x: get_risk(x))",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_uncertainty(semester_id):\n    semester=semesters_test[semesters_test[\"semester_id\"]==semester_id]\n    student_id=semester[\"student_id\"].values[0]\n    student_info=students_test[students_test[\"student_id\"]==student_id]\n    cluster_student=student_info[\"cluster\"].values[0]\n    similar_students=students_train[students_train[\"cluster\"]==cluster_student]\n    similar_students_ids=similar_students[\"student_id\"].tolist()\n    semester_cluster=semester[\"cluster\"].values[0]\n    selected_semesters=semesters_train[semesters_train[\"student_id\"].isin(similar_students_ids)]\n    selected_semesters=selected_semesters[selected_semesters['cluster']==semester_cluster]\n    total_cases=len(selected_semesters)\n    return total_cases",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "semesters_test[\"risk_uncertainty\"]=semesters_test['semester_id'].apply(lambda x: get_uncertainty(x))",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "brier_score_loss(semesters_test['fail'], semesters_test['risk_prediction'])",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "0.18530510407799886"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fraction_of_positives, mean_predicted_value = calibration_curve(semesters_test['fail'], semesters_test['risk_prediction'], n_bins=10)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\")\nplt.plot(mean_predicted_value,mean_predicted_value,'r-')",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "[<matplotlib.lines.Line2D at 0x7f9d318895f8>]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def get_new_risk_and_uncertainty(factor1,factor2,factor3,factor4,factor5,gpa,order, beta_total,num_classes):\n    columns_student=[\"factor1\",\"factor2\",\"factor3\",\"factor4\",\"factor5\",\"gpa\"]\n    columns_semester=['order', 'beta_total','num_classes']\n    student_data = pd.DataFrame([[factor1,factor2,factor3,factor4,factor5,gpa]], columns=columns_student)\n    semester_data = pd.DataFrame([[order,beta_total,num_classes]], columns=columns_semester)\n    student_cluster=clus_students.predict(student_data)[0]\n    semester_cluster=clus_semesters.predict(semester_data)[0]\n    \n    similar_students=students_train[students_train[\"cluster\"]==student_cluster]\n    similar_students_ids=similar_students[\"student_id\"].tolist()\n    \n    selected_semesters=semesters_train[semesters_train[\"student_id\"].isin(similar_students_ids)]\n    selected_semesters=selected_semesters[selected_semesters['cluster']==semester_cluster]\n    \n    total_cases=len(selected_semesters)\n    failed_cases=len(selected_semesters[selected_semesters['fail']==True])\n    risk=failed_cases/total_cases\n    return risk,total_cases",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "risk,certainty=get_new_risk_and_uncertainty(8,8,8,8,8,8,2,1,5)\nrisk,certainty",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "(0.17772215269086358, 799)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "risk,certainty=get_new_risk_and_uncertainty(5,5,5,5,5,5,2,1,5)\nrisk,certainty",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "(0.7705286839145107, 889)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Machine Learning\n\nIn many ways, machine learning is the primary means by which data science manifests itself to the broader world.\nMachine learning is where these computational and algorithmic skills of data science meet the statistical thinking of data science, and the result is a collection of approaches to inference and data exploration that are not about effective theory so much as effective computation.\n\nThe term \"machine learning\" is sometimes thrown around as if it is some kind of magic pill: *apply machine learning to your data, and all your problems will be solved!*\nAs you might expect, the reality is rarely this simple.\nWhile these methods can be incredibly powerful, to be effective they must be approached with a firm grasp of the strengths and weaknesses of each method, as well as a grasp of general concepts such as bias and variance, overfitting and underfitting, and more.\n\n### Categories of Machine Learning\n\nAt the most fundamental level, machine learning can be categorized into two main types: supervised learning and unsupervised learning.\n\n*Supervised learning* involves somehow modeling the relationship between measured features of data and some label associated with the data; once this model is determined, it can be used to apply labels to new, unknown data.\nThis is further subdivided into *classification* tasks and *regression* tasks: in classification, the labels are discrete categories, while in regression, the labels are continuous quantities.\nWe will see examples of both types of supervised learning in the following section.\n\n*Unsupervised learning* involves modeling the features of a dataset without reference to any label, and is often described as \"letting the dataset speak for itself.\"\nThese models include tasks such as *clustering* and *dimensionality reduction.*\nClustering algorithms identify distinct groups of data, while dimensionality reduction algorithms search for more succinct representations of the data.\nWe will see examples of both types of unsupervised learning in the following section.\n\nIn addition, there are so-called *semi-supervised learning* methods, which falls somewhere between supervised learning and unsupervised learning. Semi-supervised learning methods are often useful when only incomplete labels are available."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Example of supervised Machine Learning \n\nUsing the same data that at the beginning of this tutorial, we will explore how to build a model to predict if a student will fail a semester based on their academic history.\n\nFirst we need to manipulate the data to put it in a format that enable the use of machine learning models in Python.\n\nThis format is one dataframe that contains all the predictor variables, and one dataframe that contain the variable to be predicted.  In our case, the predictor variables are the different grade averages of the student plus the characteristics of the semester.  The variable to be predicted is if the student will fail or not that semester."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "full_data = pd.merge(students,semesters,on='student_id',how='inner')\ntrain_data=full_data[full_data['year']<2012]\ntest_data=full_data[full_data['year']>2011]",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now we create train and test set in the same way as before (using 2012 as the year to be predicted)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "predictors_train = train_data[['factor1','factor2','factor3','factor4','factor5','gpa','order','beta_total','num_classes']]\nlabel_train = train_data[['fail']].values\n\npredictors_test = test_data[['factor1','factor2','factor3','factor4','factor5','gpa','order','beta_total','num_classes']]\nlabel_test = test_data[['fail']].values",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import GaussianNB \nmodel = GaussianNB()                       \nmodel.fit(predictors_train, label_train.ravel())                  \npredicted_labels = model.predict(predictors_test)             ",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score\naccuracy_score(label_test, predicted_labels)",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "0.7222222222222222"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\nimport seaborn as sns;\n\nmat = confusion_matrix(label_test, predicted_labels)\n\nsns.heatmap(mat, square=True, annot=True, cbar=False)\nplt.xlabel('predicted value')\nplt.ylabel('true value');",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Hyperparameters and Model Validation\n\nThe basic recipe for applying a supervised machine learning model:\n\n* Choose a class of model\n* Choose model hyperparameters\n* Fit the model to the training data\n* Use the model to predict labels for new data\n\nThe first two pieces of this—the choice of model and choice of hyperparameters—are perhaps the most important part of using these tools and techniques effectively.\nIn order to make an informed choice, we need a way to *validate* that our model and our hyperparameters are a good fit to the data.\nWhile this may sound simple, there are some pitfalls that you must avoid to do this effectively.\n\nIn principle, model validation is very simple: after choosing a model and its hyperparameters, we can estimate how effective it is by applying it to some of the training data and comparing the prediction to the known value.\n\n#### Model validation the wrong way\n\nLet's demonstrate the naive approach to validation:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=1)\n\nfull_data = pd.merge(students,semesters,on='student_id',how='inner')\npredictors = full_data[['factor1','factor2','factor3','factor4','factor5','gpa','order','beta_total','num_classes']]\nlabel = full_data[['fail']].values\n\nmodel.fit(predictors, label.ravel())\ny_model = model.predict(predictors)\naccuracy_score(label, y_model)",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "1.0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We see an accuracy score of 1.0, which indicates that 100% of points were correctly labeled by our model!\nBut is this truly measuring the expected accuracy? Have we really come upon a model that we expect to be correct 100% of the time?\n\nAs you may have gathered, the answer is no.\nIn fact, this approach contains a fundamental flaw: *it trains and evaluates the model on the same data*.\nFurthermore, the nearest neighbor model is an *instance-based* estimator that simply stores the training data, and predicts labels by comparing new data to these stored points: except in contrived cases, it will get 100% accuracy *every time!*"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Model validation the right way: Holdout sets\n\nSo what can be done?\nA better sense of a model's performance can be found using what's known as a *holdout set*: that is, we hold back some subset of the data from the training of the model, and then use this holdout set to check the model performance.\nThis splitting can be done using the ``train_test_split`` utility in Scikit-Learn:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nX1, X2, y1, y2 = train_test_split(predictors, label, random_state=0, train_size=0.5)\n\nmodel.fit(X1, y1)\n\ny2_model = model.predict(X2)\naccuracy_score(y2, y2_model)",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "0.6756873595019885"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We see here a more reasonable result: the nearest-neighbor classifier is about 68% accurate on this hold-out set.\nThe hold-out set is similar to unknown data, because the model has not \"seen\" it before."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Model validation via cross-validation\n\nOne disadvantage of using a holdout set for model validation is that we have lost a portion of our data to the model training.\n\nIn the above case, half the dataset does not contribute to the training of the model!\nThis is not optimal, and can cause problems – especially if the initial set of training data is small.\n\nOne way to address this is to use *cross-validation*; that is, to do a sequence of fits where each subset of the data is used both as a training set and as a validation set.\n\nHere we do two validation trials, alternately using each half of the data as a holdout set.\nUsing the split data from before, we could implement it like this:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y2_model = model.fit(X1, y1.ravel()).predict(X2)\ny1_model = model.fit(X2, y2.ravel()).predict(X1)\naccuracy_score(y1, y1_model), accuracy_score(y2, y2_model)",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "(0.6762061213902819, 0.6756873595019885)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "What comes out are two accuracy scores, which we could combine (by, say, taking the mean) to get a better measure of the global model performance.\nThis particular form of cross-validation is a *two-fold cross-validation*—that is, one in which we have split the data into two sets and used each in turn as a validation set.\n\nWe could expand on this idea to use even more trials, and more folds in the data.\n\nHere we split the data into five groups, and use each of them in turn to evaluate the model fit on the other 4/5 of the data.\nThis would be rather tedious to do by hand, and so we can use Scikit-Learn's ``cross_val_score`` convenience routine to do it succinctly:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import cross_val_score\nscores=cross_val_score(model, predictors, label.ravel(), cv=5)\nscores.mean()",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "array([0.64555868, 0.66868381, 0.67574578, 0.68504107, 0.67401643])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Repeating the validation across different subsets of the data gives us an even better idea of the performance of the algorithm."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Example of Machine Learning Algorithms"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Support Vector Machines\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.svm import SVC \nmodel = SVC(gamma='scale')\ncross_val_score(model, predictors, label.ravel(), cv=5)",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "array([0.73935595, 0.73827534, 0.76437527, 0.78426286, 0.76761781])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Decision Trees"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\nscores=cross_val_score(model,predictors,label.ravel(), cv=5)\nscores.mean()",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "array([0.62999784, 0.66306462, 0.65456118, 0.68633809, 0.66904453])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Random Forest"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=0)\nscores=cross_val_score(model,predictors,label.ravel(), cv=5)\nscores.mean()",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "array([0.71363735, 0.71752756, 0.73778642, 0.75680934, 0.75205361])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Dashboard\n\nWe will create a dashboard that will present the result of the two types of models.  The clustering algorithm and a Random Forest Classifier to predict the risk of a student.\n\nThis code should be run on Spyder. Then it should be upload into a github repository and published in heroku."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}